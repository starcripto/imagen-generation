gradio>=3.50.2
pillow>=10.0.0
torch>=2.0.0
transformers>=4.36.0
diffusers>=0.24.0
accelerate>=0.25.0
safetensors>=0.4.0
xformers>=0.0.22
python-dotenv>=1.0.0
requests>=2.31.0
numpy>=1.24.0
opencv-python>=4.8.0
matplotlib>=3.7.0
tqdm>=4.65.0
huggingface_hub>=0.19.0
pydantic>=2.4.0
fastapi>=0.104.0
uvicorn>=0.24.0
python-multipart>=0.0.6
import os
import time
import requests
import io
from PIL import Image
from pathlib import Path
import torch

class ModelManager:
    """Clase para gestionar los diferentes modelos de generación de imágenes"""
    
    def __init__(self, save_dir="./output"):
        self.save_dir = Path(save_dir)
        self.save_dir.mkdir(exist_ok=True)
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self._sdxl_pipeline = None
        self._sd_inpainting = None
        self._sd_upscaler = None
    
    def _load_sdxl_pipeline(self):
        """Carga el pipeline de Stable Diffusion XL bajo demanda"""
        if self._sdxl_pipeline is None:
            try:
                from diffusers import StableDiffusionXLPipeline, DPMSolverMultistepScheduler
                
                print("Cargando modelo SDXL...")
                model_id = "stabilityai/stable-diffusion-xl-base-1.0"
                pipeline = StableDiffusionXLPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16,
                    use_safetensors=True
                )
                pipeline.scheduler = DPMSolverMultistepScheduler.from_config(
                    pipeline.scheduler.config, 
                    algorithm_type="sde-dpmsolver++", 
                    use_karras_sigmas=True
                )
                pipeline = pipeline.to(self.device)
                
                # Optimizaciones
                if self.device == "cuda":
                    pipeline.enable_xformers_memory_efficient_attention()
                
                self._sdxl_pipeline = pipeline
                print("Modelo SDXL cargado correctamente")
            except Exception as e:
                print(f"Error al cargar SDXL: {e}")
                return None
        
        return self._sdxl_pipeline
    
    def _load_inpainting_model(self):
        """Carga el modelo de inpainting bajo demanda"""
        if self._sd_inpainting is None:
            try:
                from diffusers import StableDiffusionInpaintPipeline
                
                print("Cargando modelo de inpainting...")
                model_id = "runwayml/stable-diffusion-inpainting"
                pipeline = StableDiffusionInpaintPipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16
                ).to(self.device)
                
                if self.device == "cuda":
                    pipeline.enable_xformers_memory_efficient_attention()
                
                self._sd_inpainting = pipeline
                print("Modelo de inpainting cargado correctamente")
            except Exception as e:
                print(f"Error al cargar modelo de inpainting: {e}")
                return None
        
        return self._sd_inpainting
    
    def _load_upscaler_model(self):
        """Carga el modelo de upscaling bajo demanda"""
        if self._sd_upscaler is None:
            try:
                from diffusers import StableDiffusionUpscalePipeline
                
                print("Cargando modelo de upscaling...")
                model_id = "stabilityai/stable-diffusion-x4-upscaler"
                pipeline = StableDiffusionUpscalePipeline.from_pretrained(
                    model_id,
                    torch_dtype=torch.float16
                ).to(self.device)
                
                self._sd_upscaler = pipeline
                print("Modelo de upscaling cargado correctamente")
            except Exception as e:
                print(f"Error al cargar modelo de upscaling: {e}")
                return None
        
        return self._sd_upscaler
    
    def generate_with_sdxl(self, prompt, negative_prompt="", steps=30, 
                           guidance_scale=7.5, width=1024, height=1024, seed=-1):
        """Genera una imagen con Stable Diffusion XL"""
        try:
            # Cargar pipeline
            pipeline = self._load_sdxl_pipeline()
            if pipeline is None:
                return None, "Error al cargar el modelo SDXL"
            
            # Configurar generador para reproducibilidad
            if seed == -1:
                seed = int(time.time())
            generator = torch.Generator(device=self.device).manual_seed(seed)
            
            # Generar imagen
            images = pipeline(
                prompt=prompt,
                negative_prompt=negative_prompt,
                num_inference_steps=steps,
                guidance_scale=guidance_scale,
                width=width,
                height=height,
                generator=generator
            ).images
            
            # Guardar imagen
            timestamp = int(time.time())
            save_path = self.save_dir / f"sdxl_{timestamp}_{seed}.png"
            images[0].save(save_path)
            
            return images[0], f"Imagen generada con SDXL (seed: {seed})"
        except Exception as e:
            return None, f"Error en la generación con SDXL: {str(e)}"
    
    def generate_with_dalle(self, prompt, size=(1024, 1024)):
        """Genera una imagen con DALL-E 3 a través de la API de OpenAI"""
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                return None, "Falta la clave API de OpenAI en el archivo .env"
            
            # Determinar tamaño para DALL-E
            size_map = {
                (1024, 1024): "1024x1024",
                (1024, 1792): "1024x1792",
                (1792, 1024): "1792x1024"
            }
            size_str = size_map.get((size[0], size[1]), "1024x1024")
            
            # Llamada a la API
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            payload = {
                "model": "dall-e-3",
                "prompt": prompt,
                "size": size_str,
                "quality": "hd",
                "n": 1
            }
            
            response = requests.post(
                "https://api.openai.com/v1/images/generations",
                headers=headers,
                json=payload
            )
            
            if response.status_code != 200:
                return None, f"Error en la API de OpenAI: {response.text}"
            
            # Obtener URL de la imagen
            image_url = response.json()["data"][0]["url"]
            
            # Descargar la imagen
            image_response = requests.get(image_url)
            image = Image.open(io.BytesIO(image_response.content))
            
            # Guardar imagen
            timestamp = int(time.time())
            save_path = self.save_dir / f"dalle_{timestamp}.png"
            image.save(save_path)
            
            return image, "Imagen generada con DALL-E 3"
        except Exception as e:
            return None, f"Error con DALL-E: {str(e)}"

    def generate_with_midjourney(self, prompt, width=1024, height=1024):
        """
        Genera una imagen con Midjourney a través de una API no oficial
        Nota: Requiere configurar una API no oficial, ya que Midjourney no ofrece API oficial
        """
        try:
            api_key = os.getenv("MIDJOURNEY_API_KEY")
            if not api_key:
                return None, "Falta la clave API de Midjourney en el archivo .env"
            
            # Este endpoint es hipotético, ya que Midjourney no tiene API oficial
            # Deberías reemplazarlo con un servicio real que ofrezca acceso a Midjourney
            url = "https://api.midjourney-proxy.example.com/generate"
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            payload = {
                "prompt": prompt,
                "width": width,
                "height": height,
                "quality": "high"
            }
            
            response = requests.post(url, headers=headers, json=payload)
            
            if response.status_code != 200:
                return None, f"Error en la API de Midjourney: {response.text}"
            
            # Obtener URL de la imagen (esto dependería de la API real que uses)
            image_url = response.json().get("image_url")
            
            # Descargar la imagen
            image_response = requests.get(image_url)
            image = Image.open(io.BytesIO(image_response.content))
            
            # Guardar imagen
            timestamp = int(time.time())
            save_path = self.save_dir / f"midjourney_{timestamp}.png"
            image.save(save_path)
            
            return image, "Imagen generada con Midjourney"
        except Exception as e:
            return None, f"Error con Midjourney API: {str(e)}"
    
    def upscale_image(self, image, prompt, factor=4):
        """Mejora la resolución de una imagen utilizando el upscaler de SD"""
        try:
            pipeline = self._load_upscaler_model()
            if pipeline is None:
                return None, "Error al cargar el modelo de upscaling"
            
            # Redimensionar si es necesario (el modelo tiene límites de tamaño)
            width, height = image.size
            if width > 512 or height > 512:
                # Escalar manteniendo aspecto para máximo 512px
                ratio = min(512/width, 512/height)
                new_width = int(width * ratio)
                new_height = int(height * ratio)
                image = image.resize((new_width, new_height), Image.LANCZOS)
            
            # Ejecutar upscaling
            upscaled_image = pipeline(
                prompt=prompt,
                image=image,
                noise_level=20,
                num_inference_steps=30
            ).images[0]
            
            # Guardar imagen
            timestamp = int(time.time())
            save_path = self.save_dir / f"upscaled_{timestamp}.png"
            upscaled_image.save(save_path)
            
            return upscaled_image, "Imagen mejorada correctamente"
        except Exception as e:
            return None, f"Error en upscaling: {str(e)}"
    
    def inpaint_image(self, image, mask, prompt, negative_prompt="", steps=30, guidance_scale=7.5, seed=-1):
        """Realiza inpainting en áreas enmascaradas de una imagen"""
        try:
            pipeline = self._load_inpainting_model()
            if pipeline is None:
                return None, "Error al cargar el modelo de inpainting"
            
            # Configurar generador
            if seed == -1:
                seed = int(time.time())
            generator = torch.Generator(device=self.device).manual_seed(seed)
            
            # Asegurar que la imagen y máscara tienen el mismo tamaño
            width, height = image.size
            mask = mask.resize((width, height), Image.NEAREST)
            
            # Ejecutar inpainting
            inpainted_image = pipeline(
                prompt=prompt,
                image=image,
                mask_image=mask,
                negative_prompt=negative_prompt,
                num_inference_steps=steps,
                guidance_scale=guidance_scale,
                generator=generator
            ).images[0]
            
            # Guardar imagen
            timestamp = int(time.time())
            save_path = self.save_dir / f"inpainted_{timestamp}_{seed}.png"
            inpainted_image.save(save_path)
            
            return inpainted_image, f"Inpainting realizado correctamente (seed: {seed})"
        except Exception as e:
            return None, f"Error en inpainting: {str(e)}"
import os
import gradio as gr
import torch
from PIL import Image
import numpy as np
import time
from dotenv import load_dotenv
from pathlib import Path
from models import ModelManager

# Cargar variables de entorno
load_dotenv()

# Directorio para guardar imágenes
SAVE_DIR = Path("./output")
SAVE_DIR.mkdir(exist_ok=True)

# Inicializar el administrador de modelos
model_manager = ModelManager(save_dir=SAVE_DIR)

# Verificar disponibilidad de GPU
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Usando dispositivo: {DEVICE}")

def generate_image(prompt, negative_prompt, model_choice, num_steps, guidance_scale, width, height, seed):
    """Función principal que decide qué modelo usar para la generación"""
    try:
        if model_choice == "Stable Diffusion XL":
            return model_manager.generate_with_sdxl(
                prompt, negative_prompt, num_steps, guidance_scale, width, height, seed
            )
        elif model_choice == "DALL-E 3":
            return model_manager.generate_with_dalle(prompt, (width, height))
        elif model_choice == "Midjourney (API)":
            return model_manager.generate_with_midjourney(prompt, width, height)
        else:
            return None, f"Modelo {model_choice} no implementado"
    except Exception as e:
        return None, f"Error general: {str(e)}"

def upscale_image(image, prompt):
    """Wrapper para la función de upscaling"""
    if image is None:
        return None, "Por favor, genera o sube una imagen primero"
    return model_manager.upscale_image(image, prompt)

def inpaint_image(image, mask, prompt, negative_prompt, steps, guidance_scale, seed):
    """Wrapper para la función de inpainting"""
    if image is None or mask is None:
        return None, "Se requiere una imagen y una máscara para inpainting"
    return model_manager.inpaint_image(image, mask, prompt, negative_prompt, steps, guidance_scale, seed)

def load_example(example):
    """Carga ejemplos predefinidos de prompt y ajustes"""
    if example == "Paisaje fantástico":
        return (
            "Un paisaje fantástico de montañas flotantes con cascadas, árboles bioluminiscentes, y castillos suspendidos en el aire, luz dorada del atardecer, nubes rosadas, estilo de película de fantasía de alta calidad",
            "personas, caras, dedos deformados, mal renderizado, mal dibujado, baja calidad, pixelado",
            "Stable Diffusion XL",
            40,
            7.5,
            1024,
            768,
            -1
        )
    elif example == "Retrato estilo anime":
        return (
            "Retrato de estilo anime de un samurai joven con una armadura negra detallada, cabello largo oscuro, cicatriz en la mejilla, katana desenvainada, pose dramática, luces de neón azules y moradas, estilo de Studio Ghibli mezclado con cyberpunk",
            "deformidades, proporciones extrañas, baja calidad, pixelado, formas deformadas, trazos feos, bordes mal definidos",
            "Stable Diffusion XL",
            30,
            7.0,
            768,
            1024,
            -1
        )
    elif example == "Comida fotorrealista":
        return (
            "Fotografía profesional culinaria de un postre gourmet de chocolate, decoración elegante con frutas rojas y hojas de menta, iluminación suave, fondo bokeh, profundidad de campo, estilo revista de gastronomía de lujo",
            "deformidades, alimentos poco apetitosos, aspecto artificial, texturas irreales, manchas, suciedad",
            "DALL-E 3",
            30,
            7.0,
            1024,
            1024,
            -1
        )
    return None

# Crear la interfaz con Gradio
def create_interface():
    with gr.Blocks(title="Generador de Imágenes de Alta Resolución") as app:
        gr.Markdown("""
        # 🖼️ Generador de Imágenes de Alta Resolución con IA
        
        Crea imágenes impresionantes usando los modelos de IA más avanzados.
        """)
        
        with gr.Tab("Generar"):
            with gr.Row():
                with gr.Column():
                    prompt = gr.Textbox(
                        label="Descripción de la imagen",
                        placeholder="Escribe una descripción detallada de la imagen que deseas crear...",
                        lines=5
                    )
                    negative_prompt = gr.Textbox(
                        label="Descripción negativa (lo que NO quieres en la imagen)",
                        placeholder="Elementos que deseas evitar en la imagen...",
                        lines=2
                    )
                    
                    with gr.Row():
                        model_choice = gr.Dropdown(
                            choices=["Stable Diffusion XL", "DALL-E 3", "Midjourney (API)"],
                            value="Stable Diffusion XL",
                            label="Modelo de IA"
                        )
                        seed = gr.Number(
                            value=-1,
                            label="Semilla (-1 para aleatoria)",
                            precision=0
                        )
                    
                    with gr.Accordion("Ajustes avanzados", open=False):
                        with gr.Row():
                            num_steps = gr.Slider(
                                minimum=20, maximum=100, value=30, step=1,
                                label="Pasos de inferencia"
                            )
                            guidance_scale = gr.Slider(
                                minimum=1.0, maximum=20.0, value=7.5, step=0.1,
                                label="Guidance Scale"
                            )
                        
                        with gr.Row():
                            width = gr.Dropdown(
                                choices=[512, 768, 1024, 1280, 1536, 1792],
                                value=1024,
                                label="Ancho"
                            )
                            height = gr.Dropdown(
                                choices=[512, 768, 1024, 1280, 1536, 1792],
                                value=1024,
                                label="Alto"
                            )
                    
                    with gr.Row():
                        generate_btn = gr.Button("Generar Imagen", variant="primary")
                        clear_btn = gr.Button("Limpiar", variant="secondary")
                    
                    # Ejemplos
                    gr.Markdown("### Ejemplos")
                    examples = gr.Dropdown(
                        choices=["Paisaje fantástico", "Retrato estilo anime", "Comida fotorrealista"],
                        label="Cargar ejemplo"
                    )
                
                with gr.Column():
                    result_image = gr.Image(label="Imagen generada", type="pil")
                    result_text = gr.Textbox(label="Resultado")
            
            # Eventos
            generate_btn.click(
                fn=generate_image,
                inputs=[prompt, negative_prompt, model_choice, num_steps, guidance_scale, width, height, seed],
                outputs=[result_image, result_text]
            )
            
            clear_btn.click(
                fn=lambda: (None, None, "Stable Diffusion XL", 30, 7.5, 1024, 1024, -1),
                inputs=[],
                outputs=[result_image, result_text, model_choice, num_steps, guidance_scale, width, height, seed]
            )
            
            examples.change(
                fn=load_example,
                inputs=[examples],
                outputs=[prompt, negative_prompt, model_choice, num_steps, guidance_scale, width, height, seed]
            )
        
        with gr.Tab("Edición"):
            with gr.Row():
                with gr.Column():
                    edit_image = gr.Image(label="Imagen a editar", type="pil", tool="sketch")
                    edit_prompt = gr.Textbox(
                        label="Descripción para edición",
                        placeholder="Describe lo que quieres modificar o mejorar...",
                        lines=3
                    )
                    edit_negative = gr.Textbox(
                        label="Descripción negativa",
                        placeholder="Lo que quieres evitar en la edición...",
                        lines=2
                    )
                    
                    with gr.Tab("Upscaling"):
                        upscale_btn = gr.Button("Mejorar Resolución", variant="primary")
                    
                    with gr.Tab("Inpainting"):
                        with gr.Row():
                            inpaint_steps = gr.Slider(
                                minimum=20, maximum=50, value=25, step=1,
                                label="Pasos"
                            )
                            inpaint_guidance = gr.Slider(
                                minimum=1.0, maximum=15.0, value=7.5, step=0.1,
                                label="Guidance Scale"
                            )
                            inpaint_seed = gr.Number(
                                value=-1, 
                                label="Semilla (-1 para aleatoria)",
                                precision=0
                            )
                        inpaint_btn = gr.Button("Aplicar Inpainting", variant="primary")
                
                with gr.Column():
                    edited_image = gr.Image(label="Imagen editada", type="pil")
                    edit_result = gr.Textbox(label="Resultado de la edición")
            
            # Eventos de edición
            upscale_btn.click(
                fn=upscale_image,
                inputs=[edit_image, edit_prompt],
                outputs=[edited_image, edit_result]
            )
            
            inpaint_btn.click(
                fn=inpaint_image,
                inputs=[edit_image, edit_image, edit_prompt, edit_negative, inpaint_steps, inpaint_guidance, inpaint_seed],
                outputs=[edited_image, edit_result]
            )
        
        with gr.Tab("Historial"):
            gr.Markdown("## Historial de imágenes generadas")
            gallery = gr.Gallery(
                label="Imágenes generadas",
                show_label=False,
                elem_id="gallery",
                columns=4,
                rows=2,
                object_fit="contain",
                height="auto"
            )
            refresh_btn = gr.Button("Actualizar Historial")
            
            # Lógica para cargar imágenes del directorio
            def load_images():
                images = []
                for ext in ["*.png", "*.jpg", "*.jpeg"]:
                    images.extend(list(SAVE_DIR.glob(ext)))
                
                # Ordenar por fecha de modificación (más reciente primero)
                images.sort(key=lambda x: os.path.getmtime(x), reverse=True)
                
                # Limitar a 20 imágenes más recientes
                images = images[:20]
                
                return [str(img) for img in images]
            
            refresh_btn.click(
                fn=load_images,
                inputs=[],
                outputs=[gallery]
            )
        
        with gr.Tab("Ayuda"):
            gr.Markdown("""
            ## Consejos para mejores resultados
            
            ### Prompts efectivos
            - Sé específico y detallado en tus descripciones
            - Menciona estilos artísticos (ej: "estilo acuarela", "fotorrealista")
            - Incluye información sobre iluminación y composición
            - Añade términos como "alta calidad", "detallado", "fotorrealista" para mejores resultados
            
            ### Ajustes recomendados
            - **Steps**: 30-50 para equilibrio entre calidad y velocidad
            - **Guidance Scale**: 7-9 para adherencia al prompt, valores más altos para más fidelidad
            - **Tamaño**: 1024x1024 para la mayoría de casos, rectángulos para paisajes o retratos
            
            ### Modelos
            - **Stable Diffusion XL**: Versátil, rápido si tienes GPU local
            - **DALL-E 3**: Excelente para seguir instrucciones complejas
            - **Midjourney**: Generalmente produce imágenes más artísticas y estilizadas
            
            ### Edición
            - En **Inpainting**: Dibuja sobre la imagen para marcar las áreas a modificar
            - Para **Upscaling**: Funciona mejor con imágenes pequeñas o de baja resolución
            """)
    
    return app

# Iniciar la aplicación
if __name__ == "__main__":
    app = create_interface()
    app.launch(share=False, server_name="0.0.0.0")
